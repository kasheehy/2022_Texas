---
title: "Texas2022_analysis_clean"
author: "Kirsten Sheehy"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

## Overview

The following script cleans and analyzes data from Texas 2022. Fish were collected by Kirsten Sheehy and Jon Aguiñaga. Behavioral data and fish lengths were extracted from videos and photos by Nishika Raghavan. Parasite data were collected by Dr. Jessica Stephenson's lab.

## Packages to Load
```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(lme4)
library(lmerTest)
library(lmtest)
library(pscl)
library(MASS)
library(here)
library(knitr)
library(DHARMa)
# library(glmmTMB) I think I can delete this now
library(performance)
library(emmeans)
library(ggeffects)
```

## Raw Data
```{r, echo=TRUE, message=FALSE}
parasite_data <- read.csv(here("data", "copy_RAW_parasite_data_20230428.csv"))
length_data <- read.csv(here("data", "copy_MERGE_NRkas_TexasFishMeasurements_20250702.csv"))
boris_data <- read.csv(here("data", "copy_RAW_Texas_BORISdata_20250617.csv"))
id_data <- read.csv(here("data", "copy_RAW_trial_ID_data_completeonly_20240220.csv"))
```


## Tidy Data

### Parasite Data

Rename columns to be consistent with other datasets.
```{r, echo=FALSE}
# rename columns to be consistent across data sets
parasite_data <- parasite_data %>% dplyr::rename(
  fish.id = fish.id,
  site.id = collection.site
)
```

Track down some quirks from data entry (e.g. typos) and get formatting consistent.
```{r, echo=FALSE}
# change collection.date and dissection.date to a date format (YYYY-MM-DD)
parasite_data$collection.date <- as.Date(parasite_data$collection.date,
  format = "%m/%d/%Y"
)

# some dates in the dissection date column are formatted M/D/YY or MM/DD/YY instead of MM/DD/YYYY.
# this code finds and fixes those years to match the YYYY format before we use as.Date.
parasite_data$dissection.date <- parse_date_time(parasite_data$dissection.date, orders = c("mdy", "dmy"))
# this gets rid of the time stamps
parasite_data$dissection.date <- as.Date(parasite_data$dissection.date,
  format = "%m/%d/%Y"
)

# change site names from abbreviation (WES, BR) to full (Weslaco, Brownsville)
parasite_data$site.id <- gsub("WES", "Weslaco", parasite_data$site.id)
parasite_data$site.id <- gsub("BR-OP", "Brownsville", parasite_data$site.id)

# note: the 'OP' in Brownsville stands for 'overpass'. We explored several sites
# in Brownsville, but only used the ones from the overpass for this study, so I
# simplified the name to just 'Brownsville'.

# change species names to full (P. formosa, P. latipinna)
parasite_data$species <- gsub("formosa", "P. formosa", parasite_data$species)
parasite_data$species <- gsub("latipinna", "P. latipinna", parasite_data$species)

# there were two entries for pf-59. They received different counts of parasites, so I kept both as this was clearly just a labeling issue and not a fish being counted twice. The unique ID is really only important for associating with behavioral trials. These fish did not receive behavior trials, so individual ID is not important.

# checking and fixing data structure
str(parasite_data)
parasite_data$site.id <- as.factor(parasite_data$site.id)
parasite_data$fish.id <- as.factor(parasite_data$fish.id)
parasite_data$species <- as.factor(parasite_data$species)
parasite_data$sex <- as.factor(parasite_data$sex)
parasite_data$sex.label <- as.factor(parasite_data$sex.label)
parasite_data$sex.species <- as.factor(parasite_data$sex.species)
parasite_data$totalpara <- as.numeric(parasite_data$totalpara)
str(parasite_data)

# remove blank rows (empty rows between each entry in original sheet from Jessica, probably for ease of reading)
parasite_data <- parasite_data %>%
  tidyr::drop_na(collection.date)
```

### Length Data

These measurements were done by Nishika and I in QuPath. For each image, there are three measurements: standard, total, and one labeled as the name of the file/fish.id. The file/fish.id is just the measurement we used to set the scale. Nishika measured a centimeter on the ruler in each photo, then set those pixels to equal 10000. This means that for every 10000 pixels, we have 1cm. This checks out with the measurements in the file (e.g. 30328.4 = 3.03cm). This also checks out with going back and eyeballing some measurements from random photos.

Standard length is from the mouth of the fish to the caudal peduncle. Total length is from the mouth to the tip of the tail.

Let's get the column names consistent with the other datasets.
```{r, echo=FALSE}
# renaming the columns
length_data <- length_data %>% dplyr::rename(
  file.name = Image,
  length = Length.µm
)
```

Now, let's manipulate the data so that the lengths are all in their own columns (one row per fish). Remember, the collection information and fish.id are encoded in the 10000 pixel length name (e.g. br-op_06aug_pl-1_f). We can associate the three measurements by the image file name used in QuPath (e.g. IMG_20220807_155019762.jpg)
```{r, echo=FALSE}
# pivot wider so that the fish.id, standard, and total length measurements are in their own columns.
length_data <- length_data %>%
  mutate(fish.id = if_else(str_detect(Name, "_"), Name, NA_character_)) %>%
  fill(fish.id) %>% # Fill down the fish.id so each standard/total gets its fish
  filter(Name != fish.id) %>% # Remove the rows where Name == fish.id (we already stored them)
  pivot_wider(names_from = Name, values_from = length) # Reshape wider
```

Now, let's split up the fish.id column into it's various components: site.id, date, fish.id, and sex (e.g. br-op_06aug_pl-1_f becomes Brownsville, 2022-08-06, PL-1, and F).
```{r, echo=FALSE}
# split the fish.id column into site.id, date, fish.id, and sex
length_data <- length_data %>%
  tidyr::separate_wider_delim(fish.id,
    delim = "_",
    names = c(
      "site.id",
      "date.collected",
      "fish.id",
      "sex"
    ),
    too_few = "align_start"
  )
```

Let's also get these column names to match the rest of the data.
```{r, echo=FALSE}
# make the fish.id, site.id, and sex format match the rest of the data
length_data$fish.id <- gsub("pf", "PF", length_data$fish.id)
length_data$fish.id <- gsub("pl", "PL", length_data$fish.id)
length_data$site.id <- gsub("wes", "Weslaco", length_data$site.id)
length_data$site.id <- gsub("brop", "Brownsville", length_data$site.id)
length_data$site.id <- gsub("br-op", "Brownsville", length_data$site.id)
length_data$sex <- gsub("f", "F", length_data$sex)
length_data$sex <- gsub("m", "M", length_data$sex)

# there are 3 NAs for Amazon sex. These labels were probably missing in the photo,
#  but all Amazons are females. So, let's change those.
length_data$sex <- length_data$sex %>% replace_na("F")

# change length and date.collected column names
length_data$standard.length <- length_data$standard
length_data$total.length <- length_data$total
length_data$collection.date <- length_data$date.collected
length_data <- length_data %>%
  dplyr::select(
    -standard,
    -total,
    -date.collected
  )

# formatting collection.date column
length_data$collection.date <- gsub("aug", "-08-", length_data$collection.date)
# two dates are backwards (-08-11 instead of 11-08-), fixing them here. We did no collections in November.
length_data$collection.date <- gsub("-08-11", "11-08-", length_data$collection.date)
length_data$collection.date <- paste0(length_data$collection.date, "2022")
length_data$collection.date <- as.Date(length_data$collection.date, format = "%d-%m-%Y")

# checking and fixing data structure
str(length_data)
length_data$file.name <- as.factor(length_data$file.name)
length_data$site.id <- as.factor(length_data$site.id)
length_data$fish.id <- as.factor(length_data$fish.id)
length_data$sex <- as.factor(length_data$sex)
```

there are two fish in the length data that need more specific names due to an error in how we initially recorded them in our notebooks. There are two PF-08s, one for Brownsville and one for Weslaco. The Brownsville one eventually became PF-08BR. There is also PF-25B in the boris data. I'm not sure why it was recorded that way (assuming there were two by mistake), but it is in the Weslaco site. I'm changing both of these in the length data to match the Boris data.
```{r, echo=FALSE}
# first, I need to change fish.id to a character
length_data$fish.id <- as.character(length_data$fish.id)
length_data$fish.id[length_data$fish.id == "PF-08" & length_data$site.id == "Brownsville"] <- "PF-08BR"

# changing fish.id back to a factor
length_data$fish.id <- as.factor(length_data$fish.id)

# making a simpler version of the length data
length_data_simple <- length_data[, c("fish.id", "standard.length", "total.length")]
```

### ID Data
This is the data from my lab notebook.

We just need to rename the columns to match other datasets.
```{r, echo=FALSE}
id_data <- id_data %>% dplyr::rename(
  video.id = video.ID,
  fish.id = fish.ID,
  site.id = site.ID,
  trial.id = trial.ID,
  batch.id = batch.ID
)
```

### Boris Data
This tidys up the BORIS data that Nishika collected from our videos. Basically, she recorded when the fish was on the open or sheltered half of the arena, as well as when the "startle stimulus" was applied. The startle was us slapping the water with a pool noodle.

First, let's remove unnecessary ones, create all the columns we need, and rename them to match the other datasets.
```{r, echo=FALSE}
# remove unnecessary columns (largely meta data and unused features in BORIS)
boris_data <- boris_data %>% dplyr::select(
  -Observation.date, # this is just the day processed in BORIS
  -Description,
  -FPS,
  -Behavioral.category,
  -Modifiers,
  -Comment.start,
  -Comment.stop
)

# rename columns (to match up across data)
boris_data <- boris_data %>% dplyr::rename(
  pool = Subject,
  trial.length = Total.length,
  start = Start..s.,
  stop = Stop..s.,
  duration = Duration..s.
)

# split Media.file into columns to extract file name (could also use
# Observation.id, but figured this would help avoid typos made in Boris)
boris_data <- boris_data %>% tidyr::separate_wider_delim(Media.file,
  delim = "/",
  names = c(
    "file1",
    "file2",
    "file3",
    "file4",
    "file5",
    "video.id"
  ),
  too_few = "align_end"
)

# remove the excess filepath columns
boris_data <- boris_data %>% dplyr::select(
  -file1,
  -file2,
  -file3,
  -file4,
  -file5
)

# video.id (from the file path split above) is the file name of the recording.
# It decomposes into the site ID, trial number, batch, and date recorded. The
# following code duplicates the column, then splits the information in video.id
# into separate columns.
boris_data$video.id.split <- boris_data$video.id
boris_data <- boris_data %>% tidyr::separate_wider_delim(video.id.split,
  delim = "_",
  names = c(
    "site.id",
    "trial.id",
    "batch.id",
    "trial.date"
  )
)
```

Now, let's get the values in each column formatted correctly and fix any typos.
```{r, echo=FALSE}
# remove the file type from the trial.date column
boris_data$trial.date <- gsub(".mov", "", boris_data$trial.date)

# change trial.date from (YYYYMMDD) to a date (YYYY-MM-DD)
boris_data$trial.date <- as.Date(boris_data$trial.date, format = "%Y%m%d")

# remove 'trial' from the data entries for trial.ID
boris_data$trial.id <- gsub("trial", "", boris_data$trial.id)
boris_data$trial.id <- gsub("trail", "", boris_data$trial.id) # had to find a few with a typo in the file name

# remove 'pool' from data in pool column
boris_data$pool <- gsub("Pool ", "", boris_data$pool)

# change site ID from abbreviations to full name
# note: doing them in this order is important
boris_data$site.id <- gsub("Wes", "Weslaco", boris_data$site.id)
boris_data$site.id <- gsub("WES", "Weslaco", boris_data$site.id)
boris_data$site.id <- gsub("BR1", "Brownsville", boris_data$site.id)
boris_data$site.id <- gsub("BR2", "Brownsville", boris_data$site.id)
boris_data$site.id <- gsub("BR", "Brownsville", boris_data$site.id)
# note: there are three entry types for Brownsville: BR, BR1, and BR2
# need to revisit lab notebook to confirm, but I believe BR1 and BR2
# are the two sides of the garage (i.e. the two cameras)
```

I know that I won't be using the third trial since most fish didn't get there, so I'm removing that data now.
```{r, echo=FALSE}
# removing 3rd trial since most fish didn't get three
boris_data <- boris_data %>%
  filter(trial.id == "1" |
    trial.id == "2")
```

Now that the columns are all formatted correctly, I need to pull out the behaviors from the Behavior column into their own, separate columns.
```{r, echo=FALSE}
# start by duplicating the 'Behavior' column twice. This will be used to extract start and stop times of the three behaviors (open, hiding, startle).
boris_data <- boris_data %>%
  dplyr::mutate(behavior.start = Behavior)

boris_data <- boris_data %>%
  dplyr::mutate(behavior.stop = Behavior)

# then pivot_wider with names from behavior.start and values from start
boris_data_wide <- boris_data %>%
  tidyr::pivot_wider(
    names_from = behavior.start,
    values_from = start,
    names_prefix = "start."
  )

# do the same with stop
boris_data_wide <- boris_data_wide %>%
  tidyr::pivot_wider(
    names_from = behavior.stop,
    values_from = stop,
    names_prefix = "stop."
  )

# I'll remove stop_Startle and duration_Startle because these are 'points' not 'states' and do not have a duration
boris_data_wide <- boris_data_wide %>% dplyr::select(
  -stop.Startle
)
```

Now, I need to join the ID_data and boris_data_wide datasets.
```{r, echo=FALSE}
# I need a column in both ID_data and boris_data_wide to join by
# I'll create a new column that merges the file name (which already includes
# site, trial, and batch) with pool # for both data sets

boris_data_wide$merge.id <- paste(
  boris_data_wide$video.id,
  boris_data_wide$pool
)

id_data$merge.id <- paste(
  id_data$video.id,
  id_data$pool
)

boris_data_merge <- boris_data_wide %>%
  merge(id_data, by = c("merge.id", "pool", "trial.id", "video.id"))
```

Quick note: we lose some data when we merge the id.data and boris_data_wide. It seems that we are missing five video.ids in boris_data_merge. This is probably from when we removed the third trial, which we did not do for the id_data.

Now we tidy the merged data.
```{r, echo=FALSE}
# remove duplicate columns
boris_data_merge <- boris_data_merge %>% dplyr::select(
  -merge.id,
  -site.id.y,
  -batch.id.y,
  -trial.date.y
)

# rename columns to get rid of .x and .y appendages
boris_data_merge <- boris_data_merge %>% dplyr::rename(
  site.id = site.id.x,
  batch.id = batch.id.x,
  trial.date = trial.date.x
)

# add column for species from fish.ID
boris_data_merge <- boris_data_merge %>%
  mutate(species = fish.id)

boris_data_merge <- boris_data_merge %>%
  separate_wider_delim(species,
    delim = "-",
    names = c(
      "species",
      "junk.num"
    )
  )

boris_data_merge <- boris_data_merge %>% dplyr::select(-junk.num)

# change species names to full (P. formosa, P. latipinna)
boris_data_merge$species <- gsub("PF", "P. formosa", boris_data_merge$species)
boris_data_merge$species <- gsub("PL", "P. latipinna", boris_data_merge$species)

# filling the 'start.startle' column based on fish and trial ID. This way every row has the startle time associated with it for each fish's trial.
boris_data_merge <- boris_data_merge %>%
  group_by(fish.id, trial.id) %>%
  fill(start.Startle, .direction = "downup")
```

Now, I need to standardize the trial times. When Nishika and I were observing, we sometimes recorded behaviors for longer than the prescribed 10 minutes. The following code finds the earliest behavior observation (either start.hiding or start.open) and then cuts off any observations 10 minutes after the startle.
```{r, echo=FALSE}
# new columns with the earliest open and hiding value per fish per trial
boris_data_merge <- boris_data_merge %>% 
  group_by(fish.id, trial.id) %>% 
  mutate(
    earliest.open = min(start.Open, na.rm = TRUE),
    earliest.hiding = min(start.Hiding, na.rm = TRUE)
  )

# now, we need to remove the infinite values (caused by no minimum open or hiding value)
boris_data_merge[sapply(boris_data_merge, is.infinite)] <- NA

# creates a trial cutoff time by taking the startle time
# and adding 600 seconds (10 minutes) to it
boris_data_merge <- boris_data_merge %>%
  group_by(fish.id, trial.id) %>%
  mutate(
    trial.end = start.Startle + 600
  )

# now, I need to remove all observations per fish per trial that exceed this cutoff time
boris_data_cutoff <- boris_data_merge %>%
  group_by(fish.id, trial.id) %>%
  filter(start.Open <= trial.end |
    start.Hiding <= trial.end)
  
```

Now, I am going to replace any end times that go past the prescribed trial end time (10 minutes, or 600 seconds). Nishika and I often accidentally just watched the video longer than we needed to.
```{r}
# now, I need to create an 'end cap' value to replace any 'stop' behaviors that went past the trial end time (10 minutes, or 600 seconds after the startle)
# basically, I need to close the observation (like in Boris)

# this also means I'll need to change the 'duration' columns, which are automatically
# exported from Boris.

# replace stop.Open with trial cutoff if higher than cutoff
boris_data_cutoff <- boris_data_cutoff %>%
  group_by(fish.id, trial.id) %>%
  mutate(stop.Open = if_else(stop.Open > trial.end, trial.end, stop.Open))

# replace stop.Hiding with trial cutoff if higher than cutoff
boris_data_cutoff <- boris_data_cutoff %>%
  group_by(fish.id, trial.id) %>%
  mutate(stop.Hiding = if_else(stop.Hiding > trial.end, trial.end, stop.Hiding))

# now, recalculate duration based on new end times
boris_data_cutoff <- boris_data_cutoff %>%
  group_by(fish.id, trial.id) %>%
  mutate(duration.Open = stop.Open - start.Open)

boris_data_cutoff <- boris_data_cutoff %>%
  group_by(fish.id, trial.id) %>%
  mutate(duration.Hiding = stop.Hiding - start.Hiding)
```

Now, I need to id observations that are pre vs. post startle. If they start pre-startle and end post-startle, I'll need to chop up the observation so that there are now two--one pre- and one post-startle.
```{r}
# I need to separate data into before, after, and bridging the cue start time
boris_data_cutoff <- boris_data_cutoff %>%
  group_by(fish.id, trial.id) %>%
  rowwise() %>%
  mutate(
    category = case_when(
      stop.Hiding <= start.Startle ~ "before",
      stop.Open <= start.Startle ~ "before",
      start.Hiding >= start.Startle ~ "after",
      start.Open >= start.Startle ~ "after",
      TRUE ~ "bridge"
    )
  )

# need to compute before/after times to split up the bridging observations
before_startle_data <- boris_data_cutoff %>%
  filter(category == "bridge") %>%
  mutate(stop.Open = start.Startle) %>%
  mutate(stop.Hiding = start.Startle) %>%
  mutate(duration.Hiding = (stop.Hiding - start.Hiding)) %>%
  mutate(duration.Open = (stop.Open - start.Open))

after_startle_data <- boris_data_cutoff %>%
  filter(category == "bridge") %>%
  mutate(start.Open = start.Startle) %>%
  mutate(start.Hiding = start.Startle) %>%
  mutate(duration.Hiding = (stop.Hiding - start.Hiding)) %>%
  mutate(duration.Open = (stop.Open - start.Open))

# now we bring those all back together, but first remove the bridge data
boris_data_cutoff <- boris_data_cutoff %>%
  filter(category != "bridge")

boris_data_cutoff <- rbind(boris_data_cutoff, before_startle_data)
boris_data_cutoff <- rbind(boris_data_cutoff, after_startle_data)
boris_data_cutoff <- as.data.frame(boris_data_cutoff)
```

Creating some summary data
```{r, echo=FALSE}
# summary of before startle behavior
boris_data_summary_b4 <- boris_data_cutoff %>%
  filter(stop.Hiding <= start.Startle | stop.Open <= start.Startle) %>% 
  group_by(fish.id, trial.id, site.id, species) %>% # I think the species argument is redundant, since that is coded in the fish.id
  mutate(total.time.b4 = (start.Startle - pmin(earliest.open, earliest.hiding))) %>% 
  summarise(
    total.time.hiding.b4 = sum(duration.Hiding, na.rm = TRUE),
    total.time.open.b4 = sum(duration.Open, na.rm = TRUE),
    total.behavior.switches.b4 = n(),
    total.time.b4 = mean(total.time.b4)
  )

# the way that the switches are calculated in the above code needs to be reduced by 1

boris_data_summary_b4$total.behavior.switches.b4 <- boris_data_summary_b4$total.behavior.switches.b4 - 1

# summary of after startle behavior
boris_data_summary_after <- boris_data_cutoff %>%
  filter(start.Hiding >= start.Startle | start.Open >= start.Startle) %>% 
  group_by(fish.id, trial.id, site.id, species) %>%
  mutate(total.time.after = (trial.end - start.Startle)) %>% 
  summarise(
    total.time.hiding.after = sum(duration.Hiding, na.rm = TRUE),
    total.time.open.after = sum(duration.Open, na.rm = TRUE),
    total.behavior.switches.after = n(),
    total.time.after = mean(total.time.after)
  )

# the way that the switches are calculated in the above code needs to be reduced by 1

boris_data_summary_after$total.behavior.switches.after <- boris_data_summary_after$total.behavior.switches.after - 1


# merging the before/after summaries
boris_data_summary <- left_join(boris_data_summary_b4, boris_data_summary_after, by = c("fish.id", "trial.id", "site.id", "species"))

boris_data_summary <- boris_data_summary %>% 
  group_by(fish.id, trial.id) %>% 
  mutate(prop.open.b4 = (total.time.open.b4/total.time.b4)) %>% 
  mutate(prop.open.after = (total.time.open.after/total.time.after)) %>% 
  mutate(prop.open = sum(total.time.open.b4, total.time.open.after)/sum(total.time.b4, total.time.after))
```

### All data
Merge all data into a single dataframe.
```{r, echo=FALSE}
all_data <- boris_data_summary %>%
  left_join(length_data_simple, by = "fish.id", relationship = "many-to-many")

all_data <- all_data %>%
  left_join(parasite_data, by = c("site.id", "fish.id", "species"))

all_data <- all_data %>% 
  drop_na(collection.date)
```

We did not have fraction of a second precision in our observations, so I'm removing the decimal for time values to create integers (this will also make some anlysis easier).
```{r}
all_data$total.time.hiding.b4 <- round(all_data$total.time.hiding.b4, 0)
all_data$total.time.hiding.after <- round(all_data$total.time.hiding.after, 0)
all_data$total.time.open.b4 <- round(all_data$total.time.open.b4, 0)
all_data$total.time.open.after <- round(all_data$total.time.open.after, 0)
all_data$total.time.b4 <- round(all_data$total.time.b4, 0)
all_data$total.time.after <- round(all_data$total.time.after, 0)
```

Pivot the data longer for graphing
```{r}
# pivoting data so I can plot time before/after together
all_data_long <- all_data %>% 
  pivot_longer(
    cols = starts_with("prop"),
    names_to = "prop.type",
    values_to = "proportion",
    values_drop_na = TRUE
  )

# set the prop.type order
all_data_long$prop.type <- factor(all_data_long$prop.type, levels = c("prop.open.b4", "prop.open.after", "prop.open"))
```

## Inspect Data
First, some 'dummy checks' to make sure the data make sense
```{r, echo=FALSE}
# fish.IDs
unique(id_data$fish.id) # 68 unique IDs
unique(boris_data_summary$fish.id) # 68 unique IDs
unique(parasite_data$fish.id) # 121, but 2 are just 'P.formosa' and 'P.latipina' because of how fish were labeled
unique(length_data$fish.id) # 128, but this is probably ok. We photographed way more fish for length than we got into behavioral trials
unique(all_data$fish.id) # 68 unique IDs

# video.ID
unique(boris_data_cutoff$video.id) # 28
unique(id_data$video.id) # 36
```

This all makes sense. The number of unique fish IDs from my notebook match up with the boris data. There are more parasite fish IDs because we sent Jessica extra fish that didn't go through trials. Same for fish lengths, more were photographed than went through trials.

We have fewer video IDs in the boris data because we removed trial 3. We removed trial 3 because most fish didn't make it through all three trials.

Now, let's make some histograms.
```{r}
# length data
length_hist <- all_data %>%
  ggplot(mapping = aes(standard.length)) +
  geom_histogram()
length_hist
```

Seems like a fairly normal distribution for length! Two mongo fish were over 5cm!

Let's take a look at the parasite data.
```{r}
# all parasite data
parasite_hist <- parasite_data %>%
  ggplot(mapping = aes(totalpara)) +
  geom_histogram()
parasite_hist


# parasite data for fish that went through trials
parasite_beh_hist <- all_data %>%
  ggplot(mapping = aes(totalpara)) +
  geom_histogram()
parasite_beh_hist
```

Not a normal distribution. No obvious pattern here, besides a lot of zeros. Should check to see how this matches up with notes in the parasite data about specimen quality).

Let's look at the parasites by species and site.
```{r}
# parasite data only
sp_parasite_box <- parasite_data %>%
  ggplot(mapping = aes(
    fill = species,
    x = site.id,
    y = totalpara
  )) +
  geom_boxplot()
sp_parasite_box

# behavior parasite data
# parasite data only
sp_parasite_beh_box <- all_data %>%
  ggplot(mapping = aes(
    fill = species,
    x = site.id,
    y = totalpara
  )) +
  geom_boxplot()
sp_parasite_beh_box

```

Ok, so there is a clear pattern of more parasites in Brownsville, generally. It also seems like there may be more parasites on Amazons in both sites, but we'll see what the stats say.

Now, let's take a look at the shape of the behavior data.
```{r}
# boris_data, distributions
open_hist <- all_data %>%
  ggplot(mapping = aes(prop.open)) +
  geom_histogram()
open_hist

# before startle
b4.open_hist <- all_data %>%
  ggplot(mapping = aes(prop.open.b4)) +
  geom_histogram()
b4.open_hist

# after startle
after.open_hist <- all_data %>%
  ggplot(mapping = aes(prop.open.after)) +
  geom_histogram()
after.open_hist
```

Now, let's take a look at the proportion of time spent in the open by species.
```{r}
# proportion time in open total
species_prop_total <- all_data %>%
  ggplot(mapping = aes(
    x = species,
    y = prop.open,
    fill = species
  )) +
  geom_boxplot()
species_prop_total

# proportion time in open before startle by species
species_prop_open <- all_data %>%
  ggplot(mapping = aes(
    x = species,
    y = prop.open.b4,
    fill = species
  )) +
  geom_boxplot()
species_prop_open

# proportion time in open after startle
species_prop_after <- all_data %>%
  ggplot(mapping = aes(
    x = species,
    y = prop.open.after,
    fill = species
  )) +
  geom_boxplot()
species_prop_after
```

Ok, now I want to plot before/after within species. Need to use the all_data_long.
```{r}
# proportion time before/after by species
prop_time_total <- all_data_long %>%
  ggplot(mapping = aes(
    x = prop.type,
    y = proportion,
    fill = species
  )) +
  geom_boxplot()
prop_time_total
```

We'll see how the stats pan out, but it looks like Amazons might spend more time in the open than sailfins in general, and especially after the startle!
## Models
### Parasites

First, I want to see if there is a difference in parasite load between Amazons and Sailfins. This will be using the full dataset from Jessica, which includes fish that did not go through behavioral trials. We'll start with both sites, but I may just end up looking at the Weslaco site since that is a more balanced dataset.

I kind of know already that these are going to be quite zero inflated, but let's start with a full linear model to confirm.
```{r}
mod_full <- lm(totalpara ~ species * site.id,
  data = parasite_data
)

# to run all the tests in DHARMa, you first have to simulate your residuals
sim.mod_full <- DHARMa::simulateResiduals(mod_full)

# then you can plot them
plot(sim.mod_full) # op, both of these look pretty bad
plotResiduals(sim.mod_full)
# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.mod_full) # dispersion looks ok, but the QQ plot is bad

# yes we can see that the data is super zero inflated
DHARMa::testZeroInflation(sim.mod_full) # yep, super zero inflated
```

Ok, so the data is zero inflated. We will need to run two models: a count model that excludes the zeros, and a binomial model that deals with the zeros (zero or greater than zero). So we need to test the fit of different kinds of models (poisson or possibly binomial) for both the count and binomial model.

##### Count model
Let's look at the count model first. We'll filter the data to exclude the zeros. Those will be dealt with in the other, zero inflation model.
```{r}
# filtering data to exclude zeros
parasite_data_nozeros <- parasite_data %>% 
  filter(totalpara > 0)

# test which distribution is best
mod_full_gaussian <- glm(totalpara ~ species * site.id,
                        family = gaussian(link = "identity"),
                        data = parasite_data_nozeros
                        )

mod_full_poisson <- glm(totalpara ~ species * site.id,
                        family = poisson(link = "log"),
                        data = parasite_data_nozeros
                        )

mod_full_nbin <- glm.nb(totalpara ~ species * site.id,
                        data = parasite_data_nozeros
                        )

# let's compare dispersion
check_overdispersion(mod_full_gaussian) # data is not over dispersed
check_overdispersion(mod_full_poisson) # data is over dispersed
check_overdispersion(mod_full_nbin) # data is not over dispersed

lrtest(mod_full_gaussian, mod_full_nbin) # there is a sig difference between the two, with nbin having a lower loglik
```

Ok, so for the count model we'll use a negative binomial distribution.

Now, let's do some backwards model selection for the count model.
```{r}
# interaction model
mod_full_nbin <- glm.nb(totalpara ~ species * site.id,
                        data = parasite_data_nozeros
                        )

# no interaction model
mod_combined_nbin <- glm.nb(totalpara ~ species + site.id,
                        data = parasite_data_nozeros
                        )
# test 2-way with log likelihood ratio test
lrtest(mod_full_nbin, mod_combined_nbin) # no difference, so let's go with the simpler, combined model
```

Ok let's more forward with the combined count model. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_nbin)

# then you can plot them
plot(sim.output) # QQ plot not perfect, within-group deviations from uniformity significant. Not sure how to deal with the within-group issue.

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # all look ok

# from poking around, it seems like estimating overdispersion is how we evaluate goodness of fit (versus an r-squared). Not sure if that is the correct move, but here we go. I also used this earlier on to evaluate whether I should use a negbin or poisson.
check_overdispersion(mod_combined_nbin) # no overdispersion detected. dispersion ratio = 0.702 p = 0.656
```

##### Binary model

Now, let's look at the zero inflated model. We'll need to make a column that turns parasite absence and presence into a binary (0 or 1).
```{r}
# make column with binary value for infection status
parasite_data$binary.status <- ifelse(parasite_data$totalpara == 0,0,1)

# now, let's test which distribution is best

mod_full_zi_binom <- glm(binary.status ~ species * site.id,
                        family = binomial(link = "logit"),
                        data = parasite_data
                        )

mod_full_zi_poisson <- glm(binary.status ~ species * site.id,
                        family = poisson(link = "log"),
                        data = parasite_data
                        )

mod_full_zi_nbin <- glm.nb(binary.status ~ species * site.id,
                          data = parasite_data) # warning error about iteration limit indicates data is underdispersed. This is confirmed with the dispersion test below.

# let's compare dispersion
check_overdispersion(mod_full_zi_binom) # data is not over dispersed
check_overdispersion(mod_full_zi_poisson) # data is not over dispersed
check_overdispersion(mod_full_zi_nbin) # data is under dispersed

lrtest(mod_full_zi_binom, mod_full_zi_poisson) # significant difference, and the binomial model has a lower log lik
# checking with anova
anova(mod_full_zi_binom, mod_full_zi_poisson) # there is a difference, but the poisson model has a lower residual deviation
```

Ok, I'm just going to go ahead with the binomial model since that makes more sense here and seems "good enough". Let's check those assumptions.

Now, let's do some backwards model selection for the binomial model.
```{r}
# interaction model
mod_full_zi_binom <- glm(binary.status ~ species * site.id,
                        family = binomial(link = "logit"),
                        data = parasite_data
                        )

# no interaction model
mod_combined_zi_binom <- glm(binary.status ~ species + site.id,
                        family = binomial(link = "logit"),
                        data = parasite_data
                        )
# test 2-way with log likelihood ratio test
lrtest(mod_full_zi_binom, mod_combined_zi_binom) # no sig difference, so let's go with the simpler, combined model
```

Ok let's more forward with the combined binomial model. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_zi_binom)

# then you can plot them
plot(sim.output) # looks ok

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # looks ok

# check dispersion of combined
check_overdispersion(mod_combined_zi_binom) # no overdispersion detected. dispersion ratio = 1.012 p = 0.896
```

##### Conclusions
Let's take a look at our final models.
```{r}
summary(mod_combined_nbin) # species insignificant (est = -0.02, SE = 0.28, p = 0.925) and site highly significant in count model (est = -2.26, SE = 0.29, p = 2.48e-15).

summary(mod_combined_zi_binom) # species significant (est = -1.51, SE = 0.47, p = 0.0.001424) and site significant in binomial model (est = -2.77, SE = 0.80, p = 0.000516).
```

Ok now lets dig into those effect sizes
```{r}

## count model ##

# species in the count model
mod_sp_combined_nbin <- glm.nb(totalpara ~ site.id,
                        data = parasite_data_nozeros
                        )

lrtest(mod_combined_nbin, mod_sp_combined_nbin) # log likelihood ratio -428.80, p = 0.9219

# site.id in the count model
mod_site_combined_nbin <- glm.nb(totalpara ~ species,
                        data = parasite_data_nozeros
                        )

lrtest(mod_combined_nbin, mod_site_combined_nbin) # log likelihood ratio -456.58, p = 9.054e-14


## binomial model ##

# species in the binomial model
mod_sp_zi_binom <- glm(binary.status ~ site.id,
                        family = binomial(link = "logit"),
                        data = parasite_data
                        )

lrtest(mod_combined_zi_binom, mod_sp_zi_binom) # log likelihood ratio -64.403, p = 0.001016

# site.id in the binomial model
mod_site_zi_binom <- glm(binary.status ~ species,
                        family = binomial(link = "logit"),
                        data = parasite_data
                        )

lrtest(mod_combined_zi_binom, mod_site_zi_binom) # log likelihood ratio -68.956, p = 8.146e-06
```

And now we evaluate model fit with the performance package
```{r}
# count model
model_performance(mod_combined_nbin)

# binomial model
model_performance(mod_combined_zi_binom)
```

Now, let's convert those effect sizes for each model into probabilities.
```{r}
## count model, nbin ##

# only site:Weslaco significant
(exp(-2.26)-1)*100 # Fish from Weslaco have 89.56% fewer parasites.


## binomial model ##

# Species:Sailfin
exp(-1.51)/(1+exp(-1.51))*100 # Sailfins are 18.09% more likely to have no parasites.

# site:Weslaco
exp(-2.77)/(1+exp(-2.77))*100 # Fish from Weslaco are 5.90% more likely to have no parasites.
```

#### Brownsville
Now, let's essentially repeat that analysis with just the Brownsville site.

###### Br Count model
Let's look at the count model first. We'll filter the data to exclude the zeros. Those will be dealt with in the other, zero inflation model.
```{r}
# filter data to just Brownsville
parasite_data_nozeros_br <- parasite_data_nozeros %>%
  filter(site.id == "Brownsville")

# test which distribution is best
mod_full_gaussian_br <- glm(totalpara ~ species,
                        family = gaussian(link = "identity"),
                        data = parasite_data_nozeros_br
                        )

mod_full_poisson_br <- glm(totalpara ~ species,
                        family = poisson(link = "log"),
                        data = parasite_data_nozeros_br
                        )

mod_full_nbin_br <- glm.nb(totalpara ~ species,
                        data = parasite_data_nozeros_br
                        )

# let's compare dispersion
check_overdispersion(mod_full_gaussian_br) # data is not over dispersed
check_overdispersion(mod_full_poisson_br) # data is over dispersed
check_overdispersion(mod_full_nbin_br) # data is not over dispersed

lrtest(mod_full_gaussian_br, mod_full_nbin_br) # there is a sig difference between the two, with nbin having a lower loglik
```

Ok, so for the count model we'll use a negative binomial distribution. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_full_nbin_br)

# then you can plot them
plot(sim.output) # QQ plot not perfect, within-group deviations from uniformity significant. Not sure how to deal with the within-group issue.

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # all look ok

check_overdispersion(mod_full_nbin_br) # no overdispersion detected.
```

###### BrBinary model

Now, let's look at the zero inflated model. We'll need to make a column that turns parasite absence and presence into a binary (0 or 1).
```{r}
# filter data to just Brownsville
parasite_data_br <- parasite_data %>%
  filter(site.id == "Brownsville")
# now, let's test which distribution is best

mod_full_zi_binom_br <- glm(binary.status ~ species,
                        family = binomial(link = "logit"),
                        data = parasite_data_br
                        )

mod_full_zi_poisson_br <- glm(binary.status ~ species,
                        family = poisson(link = "log"),
                        data = parasite_data_br
                        )

mod_full_zi_nbin_br <- glm.nb(binary.status ~ species,
                          data = parasite_data_br) # warning error about iteration limit indicates data is underdispersed. This is confirmed with the dispersion test below.

# let's compare dispersion
check_overdispersion(mod_full_zi_binom_br) # data is not over dispersed
check_overdispersion(mod_full_zi_poisson_br) # data is not over dispersed
check_overdispersion(mod_full_zi_nbin_br) # data is under dispersed

lrtest(mod_full_zi_binom_br, mod_full_zi_poisson_br) # significant difference, and the binomial model has a lower log lik
```

Ok, I'm just going to go ahead with the binomial model since that makes more sense here and seems "good enough". Let's check those assumptions.

```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_full_zi_binom_br)

# then you can plot them
plot(sim.output) # looks ok

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # looks ok

# check dispersion of combined
check_overdispersion(mod_full_zi_binom_br) # no overdispersion detected.
```

###### Br Conclusions
Let's take a look at our final models.
```{r}
summary(mod_full_nbin_br) # species insignificant (est = -0.257, SE = 0.386, p = 0.482)

summary(mod_full_zi_binom_br) # species insignificant (est = -17.04, SE = 3242.46, p = 0.996)
```

Ok now lets dig into those effect sizes
```{r}

## count model ##

# species in the count model
mod_sp_full_nbin_br <- glm.nb(totalpara ~ 1,
                        data = parasite_data_nozeros_br
                        )

lrtest(mod_full_nbin_br, mod_sp_full_nbin_br) # log likelihood ratio -211.04, p = 0.477

## binomial model ##

# species in the binomial model
mod_sp_zi_binom_br <- glm(binary.status ~ 1,
                        family = binomial(link = "logit"),
                        data = parasite_data_br
                        )

lrtest(mod_full_zi_binom_br, mod_sp_zi_binom_br) # log likelihood ratio -7.835, p = 0.2348

# site.id in the binomial model
mod_site_zi_binom <- glm(binary.status ~ species,
                        family = binomial(link = "logit"),
                        data = parasite_data
                        )

lrtest(mod_combined_zi_binom, mod_site_zi_binom) # log likelihood ratio -68.956, p = 8.146e-06
```

And now we evaluate model fit with the performance package
```{r}
# count model
model_performance(mod_full_nbin_br)

# binomial model
model_performance(mod_full_zi_binom_br)
```

#### Weslaco
Now, let's essentially repeat that analysis with just the Weslaco site.

###### Wes Count model
Let's look at the count model first. We'll filter the data to exclude the zeros. Those will be dealt with in the other, zero inflation model.
```{r}
# filter data to just Brownsville
parasite_data_nozeros_wes <- parasite_data_nozeros %>%
  filter(site.id == "Weslaco")

# test which distribution is best
mod_full_gaussian_wes <- glm(totalpara ~ species,
                        family = gaussian(link = "identity"),
                        data = parasite_data_nozeros_wes
                        )

mod_full_poisson_wes <- glm(totalpara ~ species,
                        family = poisson(link = "log"),
                        data = parasite_data_nozeros_wes
                        )

mod_full_nbin_wes <- glm.nb(totalpara ~ species,
                        data = parasite_data_nozeros_wes
                        )

# let's compare dispersion
check_overdispersion(mod_full_gaussian_wes) # data is not over dispersed
check_overdispersion(mod_full_poisson_wes) # data is over dispersed
check_overdispersion(mod_full_nbin_wes) # data is over dispersed

lrtest(mod_full_gaussian_wes, mod_full_nbin_wes) # there is a sig difference between the two, with nbin having a lower loglik
```

Ok, so for the count model we'll use a negative binomial distribution. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_full_nbin_wes)

# then you can plot them
plot(sim.output) # QQ plot not great

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # QQ plot not good

# check dispersion of combined
check_overdispersion(mod_full_nbin_wes) # overdispersion detected.
```
Not too sure what to do here. The gaussian model is not over dispersed, but the QQ plot looks worse than the negative binomial model. For now, going to stick with the nbin model for consistency.

###### Wes Binary model

Now, let's look at the zero inflated model. We'll need to make a column that turns parasite absence and presence into a binary (0 or 1).
```{r}
# filter data to just Weslaco
parasite_data_wes <- parasite_data %>%
  filter(site.id == "Weslaco")
# now, let's test which distribution is best

mod_full_zi_binom_wes <- glm(binary.status ~ species,
                        family = binomial(link = "logit"),
                        data = parasite_data_wes
                        )

mod_full_zi_poisson_wes <- glm(binary.status ~ species,
                        family = poisson(link = "log"),
                        data = parasite_data_wes
                        )

mod_full_zi_nbin_wes <- glm.nb(binary.status ~ species,
                          data = parasite_data_wes) # warning error about iteration limit indicates data is underdispersed. This is confirmed with the dispersion test below.

# let's compare dispersion
check_overdispersion(mod_full_zi_binom_wes) # data is not over dispersed
check_overdispersion(mod_full_zi_poisson_wes) # data is not over dispersed
check_overdispersion(mod_full_zi_nbin_wes) # data is under dispersed

lrtest(mod_full_zi_binom_wes, mod_full_zi_poisson_wes) # significant difference, and the binomial model has a lower log lik
```

Ok, I'm just going to go ahead with the binomial model since that makes more sense here and seems "good enough". Let's check those assumptions.

```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_full_zi_binom_wes)

# then you can plot them
plot(sim.output) # looks ok

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # looks ok

# check dispersion of combined
check_overdispersion(mod_full_zi_binom_wes) # no overdispersion detected.
```

###### Wes Conclusions
Let's take a look at our final models.
```{r}
summary(mod_full_nbin_wes) # species insignificant (est = 0.1364, SE = 0.398, p = 0.732)

summary(mod_full_zi_binom_wes) # species significant (est = -1.469, SE = 0.480, p = 0.002)
```

Ok now lets dig into those effect sizes
```{r}

## count model ##

# species in the count model
mod_sp_full_nbin_wes <- glm.nb(totalpara ~ 1,
                        data = parasite_data_nozeros_wes
                        )

lrtest(mod_full_nbin_wes, mod_sp_full_nbin_wes) # log likelihood ratio = 215.95, p = 0.729

## binomial model ##

# species in the binomial model
mod_sp_zi_binom_wes <- glm(binary.status ~ 1,
                        family = binomial(link = "logit"),
                        data = parasite_data_wes
                        )

lrtest(mod_full_zi_binom_wes, mod_sp_zi_binom_wes) # log likelihood ratio = 56.568, p = 0.002
```

And now we evaluate model fit with the performance package
```{r}
# count model
model_performance(mod_full_nbin_wes)

# binomial model
model_performance(mod_full_zi_binom_wes)
```

### Behavior

#### Time
Ok now we'd need to see if behavior overall, before the stimulus, and after the stimulus differs between species and parasite load.

Let's look at the time spent in the open after the startle stimulus, as that is the most relevant behavioral metric (since parasites can affect anti-pred behavior, like swimming in the open)

```{r}
# FULL model, with three-way interaction
mod_beh_full <- lm(total.time.open.after ~ species * site.id * totalpara + standard.length,
                   data = all_data)

# to run all the tests in DHARMa, you first have to simulate your residuals
sim.mod_beh <- DHARMa::simulateResiduals(mod_beh_full)

# then you can plot them
plot(sim.mod_beh) # these both look not great

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.mod_beh) # dispersion looks ok, but the QQ plot is bad and outlier test is significant

# yes we can see that the data is zero inflated
DHARMa::testZeroInflation(sim.mod_beh) # yep, zero inflated

```

Ok, so the data is zero inflated. We will need to run two models: a count model that excludes the zeros, and a binomial model that deals with the zeros (zero or greater than zero). So we need to test the fit of different kinds of models (poisson or possibly binomial) for the count model.

##### Count model
Let's look at the count model first. We'll filter the data to exclude the zeros. Those will be dealt with in the other, zero inflation model.
```{r}
# filtering data to exclude zeros
beh_data_nozeros <- all_data %>% 
  filter(total.time.open.after > 0)

# test which distribution is best
mod_full_gaussian <- glm(total.time.open.after ~ species * site.id * totalpara + standard.length,
                        family = gaussian(link = "identity"),
                        data = beh_data_nozeros
                        )

mod_full_poisson <- glm(total.time.open.after ~ species * site.id * totalpara + standard.length,
                        family = poisson(link = "log"),
                        data = beh_data_nozeros
                        )

mod_full_nbin <- glm.nb(total.time.open.after ~ species * site.id * totalpara + standard.length,
                        data = beh_data_nozeros
                        )

# let's compare dispersion
check_overdispersion(mod_full_gaussian) # data is not over dispersed
check_overdispersion(mod_full_poisson) # data is over dispersed
check_overdispersion(mod_full_nbin) # data is not over dispersed

lrtest(mod_full_gaussian, mod_full_nbin) # there is a sig difference between the two, with nbin having a lower loglik
```

Ok, so for the count model we'll use a negative binomial distribution.

Now, let's do some backwards model selection for the count model.
```{r}
# interaction model
mod_full_nbin <- glm.nb(total.time.open.after ~ species * site.id * totalpara + standard.length,
                        data = beh_data_nozeros
                        )

# dropping length
mod_nolength_nbin <- glm.nb(total.time.open.after ~ species * site.id * totalpara,
                        data = beh_data_nozeros
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_full_nbin, mod_nolength_nbin) # no sig difference, so let's drop standard length

# no interaction model
mod_combined_nbin <- glm.nb(total.time.open.after ~ species + site.id + totalpara,
                        data = beh_data_nozeros
                        )
# test 2-way with log likelihood ratio test
lrtest(mod_nolength_nbin, mod_combined_nbin) # no sig difference, so let's go with the simpler, combined model
```

Ok let's more forward with the combined count model. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_nbin)

# then you can plot them
plot(sim.output) # these look fine

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # all look ok

check_overdispersion(mod_combined_nbin) # no overdispersion detected. dispersion ratio = 0.797 p = 0.652
```

##### Binary model

Now, let's look at the zero inflated model. We'll need to make a column that turns time in the open into a binary (0 or 1 for no time or some time in the open).
```{r}
# make column with binary value for infection status
all_data$binary.status <- ifelse(all_data$total.time.open.after == 0,0,1)

# now, let's test which distribution is best

mod_full_zi_binom <- glm(binary.status ~ species * site.id * totalpara + standard.length,
                         family = binomial(link = "logit"),
                        data = all_data
                        )

mod_full_zi_poisson <- glm(binary.status ~ species * site.id * totalpara + standard.length,
                        family = poisson(link = "log"),
                        data = all_data
                        )
                        

mod_full_zi_nbin <- glm.nb(binary.status ~ species * site.id * totalpara + standard.length,
                          data = all_data) # warning error about iteration limit indicates data is underdispersed. This is confirmed with the dispersion test below.

# let's compare dispersion
check_overdispersion(mod_full_zi_binom) # data is not over dispersed
check_overdispersion(mod_full_zi_poisson) # data is not over dispersed
check_overdispersion(mod_full_zi_nbin) # data is under dispersed

lrtest(mod_full_zi_binom, mod_full_zi_poisson) # significant difference, and the binomial model has a lower log lik
```

Ok, I'm going to go ahead with the binomial model since that makes more sense here and seems "good enough". Let's check those assumptions.

Now, let's do some backwards model selection for the binomial model.
```{r}
# interaction model
mod_full_zi_binom <- glm(binary.status ~ species * site.id * totalpara + standard.length,
                         family = binomial(link = "logit"),
                        data = all_data
                        )
# dropping length
mod_nolength_zi_binom <- glm(binary.status ~ species * site.id * totalpara,
                         family = binomial(link = "logit"),
                        data = all_data
                        )
# test 2-way with log likelihood ratio test
lrtest(mod_full_zi_binom, mod_nolength_zi_binom) # no sig difference, so let's go with the simpler, combined model

# no interaction model
mod_combined_zi_binom <- glm(binary.status ~ species + site.id + totalpara,
                         family = binomial(link = "logit"),
                        data = all_data
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_nolength_zi_binom, mod_combined_zi_binom) # no sig difference, so let's go with the simpler, combined model
```

Ok let's more forward with the combined binomial model. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_zi_binom)

# then you can plot them
plot(sim.output) # looks ok

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # looks ok

# check dispersion of combined
check_overdispersion(mod_combined_zi_binom) # no overdispersion detected. dispersion ratio = 1.012 p = 0.896
```

##### Conclusions
Let's take a look at our final models.
```{r}
summary(mod_combined_nbin) # species not significant (est = -0.24, SE = 0.20, p = 0.24). Site also not significant in count model (est = -0.49, SE = 0.26, p = 0.067). Total parasite is significant (est = -0.002, SE = 0.001, p = 0.0442).

summary(mod_combined_zi_binom) # species significant (est = -1.23, SE = 0.42, p = 0.00343 and site significant in binomial model (est = -0.86, SE = 0.36, p = 0.01853.
```

Ok now lets dig into those effect sizes
```{r}

## count model ##

# species in the count model
mod_sp_combined_nbin <- glm.nb(total.time.open.after ~ site.id + totalpara,
                        data = beh_data_nozeros
                        )

lrtest(mod_combined_nbin, mod_sp_combined_nbin) # log likelihood ratio -409.21, p = 0.2454

# site.id in the count model
mod_site_combined_nbin <- glm.nb(total.time.open.after ~ species + totalpara,
                        data = beh_data_nozeros
                        )

lrtest(mod_combined_nbin, mod_site_combined_nbin) # log likelihood ratio -410.17, p = 0.0707

# parasite in the count model
mod_para_combined_nbin <- glm.nb(total.time.open.after ~ site.id + species,
                        data = beh_data_nozeros
                        )

lrtest(mod_combined_nbin, mod_para_combined_nbin) # log likelihood ratio -409.81, p = 0.1102

## binomial model ##

# species in the binomial model
mod_sp_zi_binom <- glm(binary.status ~ site.id + totalpara,
                         family = binomial(link = "logit"),
                        data = all_data
                        )

lrtest(mod_combined_zi_binom, mod_sp_zi_binom) # log likelihood ratio -83.846, p = 0.0007882

# site.id in the binomial model
mod_site_zi_binom <- glm(binary.status ~ species + totalpara,
                         family = binomial(link = "logit"),
                        data = all_data
                        )

lrtest(mod_combined_zi_binom, mod_site_zi_binom) # log likelihood ratio -80.543, p = 0.03082

# parasites in the binomial model
mod_para_zi_binom <- glm(binary.status ~ site.id + species,
                         family = binomial(link = "logit"),
                        data = all_data
                        )

lrtest(mod_combined_zi_binom, mod_para_zi_binom) # log likelihood ratio -78.557, p = 0.4057
```

And now we evaluate model fit with the performance package
```{r}
# count model
model_performance(mod_combined_nbin)

# binomial model
model_performance(mod_combined_zi_binom)
```

Now, let's convert those effect sizes for each model into probabilities.
```{r}
## count model ##

# totalpara
(exp(-0.002)-1)*100 # For every increase of 1 parasite, there is a 0.20% decrease in the amount of time spent in the open.

## binomial model ##

# Species:Sailfin
exp(-1.404)/(1+exp(-1.404))*100 # There is a 19.72% decrease in the likelihood that Sailfins spend any time in the open.

# site:Weslaco
exp(1.006)/(1+exp(1.006))*100 # There is a 73.22% increase in the likelihood that fish from Weslaco spend any time in the open.
```

##### Brownsville
Now let's repeat that analysis with just the Brownsville site.

###### Br Count model
Let's look at the count model first. We'll filter the data to exclude the zeros. Those will be dealt with in the other, zero inflation model.
```{r}
# filtering data to just brownsville
beh_data_nozeros_br <- beh_data_nozeros %>% 
  filter(site.id == "Brownsville")

# test which distribution is best
mod_full_gaussian_br <- glm(total.time.open.after ~ species * totalpara + standard.length,
                        family = gaussian(link = "identity"),
                        data = beh_data_nozeros_br
                        )

mod_full_poisson_br <- glm(total.time.open.after ~ species * totalpara + standard.length,
                        family = poisson(link = "log"),
                        data = beh_data_nozeros_br
                        )

mod_full_nbin_br <- glm.nb(total.time.open.after ~ species * totalpara + standard.length,
                        data = beh_data_nozeros_br
                        )

# let's compare dispersion
check_overdispersion(mod_full_gaussian_br) # data is not over dispersed
check_overdispersion(mod_full_poisson_br) # data is over dispersed
check_overdispersion(mod_full_nbin_br) # data is not over dispersed

lrtest(mod_full_gaussian_br, mod_full_nbin_br) # there is a sig difference between the two, with nbin having a lower loglik
```

Ok, so for the count model we'll use a negative binomial distribution.

Now, let's do some backwards model selection for the count model.
```{r}
# interaction model
mod_full_nbin_br <- glm.nb(total.time.open.after ~ species * totalpara + standard.length,
                        data = beh_data_nozeros_br
                        )

# dropping length
mod_nolength_nbin_br <- glm.nb(total.time.open.after ~ species* totalpara,
                        data = beh_data_nozeros_br
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_full_nbin_br, mod_nolength_nbin_br) # no sig difference, so let's drop standard length

# no interaction model
mod_combined_nbin_br <- glm.nb(total.time.open.after ~ species + totalpara,
                        data = beh_data_nozeros_br
                        )
# test 2-way with log likelihood ratio test
lrtest(mod_nolength_nbin_br, mod_combined_nbin_br) # no sig difference, so let's go with the simpler, combined model
```

Ok let's more forward with the combined count model. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_nbin_br)

# then you can plot them
plot(sim.output) # these look fine

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # all look ok

check_overdispersion(mod_combined_nbin_br) # no overdispersion detected.
```

###### Br Binary model
```{r}
# filtering data to just brownsville
all_data_br <- all_data %>% 
  filter(site.id == "Brownsville")

# now, let's test which distribution is best

mod_full_zi_binom_br <- glm(binary.status ~ species * totalpara + standard.length,
                         family = binomial(link = "logit"),
                        data = all_data_br
                        )

mod_full_zi_poisson_br <- glm(binary.status ~ species * totalpara + standard.length,
                        family = poisson(link = "log"),
                        data = all_data_br
                        )
                        

mod_full_zi_nbin_br <- glm.nb(binary.status ~ species * totalpara + standard.length,
                          data = all_data_br) # warning error about iteration limit indicates data is underdispersed. This is confirmed with the dispersion test below.

# let's compare dispersion
check_overdispersion(mod_full_zi_binom_br) # data is not over dispersed
check_overdispersion(mod_full_zi_poisson_br) # data is not over dispersed
check_overdispersion(mod_full_zi_nbin_br) # data is under dispersed

lrtest(mod_full_zi_binom_br, mod_full_zi_poisson_br) # significant difference, and the binomial model has a lower log lik
```

Ok, I'm going to go ahead with the binomial model since that makes more sense here and seems "good enough". Let's check those assumptions.

Now, let's do some backwards model selection for the binomial model.
```{r}
# interaction model
mod_full_zi_binom_br <- glm(binary.status ~ species * totalpara + standard.length,
                         family = binomial(link = "logit"),
                        data = all_data_br
                        )
# dropping length
mod_nolength_zi_binom_br <- glm(binary.status ~ species * totalpara,
                         family = binomial(link = "logit"),
                        data = all_data_br
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_full_zi_binom_br, mod_nolength_zi_binom_br) # no sig difference, so let's go with the simpler, combined model

# no interaction model
mod_combined_zi_binom_br <- glm(binary.status ~ species + totalpara,
                         family = binomial(link = "logit"),
                        data = all_data_br
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_nolength_zi_binom_br, mod_combined_zi_binom_br) # no sig difference, so let's go with the simpler, combined model
```

Ok let's more forward with the combined binomial model. Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_zi_binom_br)

# then you can plot them
plot(sim.output) # looks ok

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # looks ok

# check dispersion of combined
check_overdispersion(mod_combined_zi_binom_br) # no overdispersion detected. dispersion ratio = 1.012 p = 0.896
```

###### Br Conclusions
Let's take a look at our final models.
```{r}
summary(mod_combined_nbin_br) # species not significant (est = 0.149, SE = 0.464, p = 0.748), total para not significant (est = -.002, SE = 0.001, p = 0.094)

summary(mod_combined_zi_binom_br) # species not significant, total para not significant
```

Ok now lets dig into those effect sizes
```{r}

## count model ##

# species in the count model
mod_sp_combined_nbin_br <- glm.nb(total.time.open.after ~ totalpara,
                        data = beh_data_nozeros_br
                        )

lrtest(mod_combined_nbin_br, mod_sp_combined_nbin_br) # log likelihood ratio -130.90, p = 0.740

# totalpara in the count model
mod_para_combined_nbin_br <- glm.nb(total.time.open.after ~ species,
                        data = beh_data_nozeros_br
                        )

lrtest(mod_combined_nbin_br, mod_para_combined_nbin_br) # log likelihood ratio -131.91, p = 0.144

## binomial model ##

# species in the binomial model
mod_sp_zi_binom_br <- glm(binary.status ~ totalpara,
                         family = binomial(link = "logit"),
                        data = all_data_br
                        )

lrtest(mod_combined_zi_binom_br, mod_sp_zi_binom_br) # log likelihood ratio -34.031, p = 0.083

# parasites in the binomial model
mod_para_zi_binom_br <- glm(binary.status ~ species,
                         family = binomial(link = "logit"),
                        data = all_data_br
                        )

lrtest(mod_combined_zi_binom_br, mod_para_zi_binom_br) # log likelihood ratio -32.823, p = 0.439
```
##### Weslaco
One more time! With Weslaco.

Let's create a Weslaco-only dataset.
```{r}
wes_data <- all_data %>% 
  filter(site.id == "Weslaco")
```

###### Wes Count model
Let's look at the count model first. We'll filter the data to exclude the zeros. Those will be dealt with in the other, zero inflation model.
```{r}
# filtering data to exclude zeros
beh_data_nozeros_wes <- wes_data %>% 
  filter(total.time.open.after > 0)

# test which distribution is best
mod_full_gaussian_wes <- glm(total.time.open.after ~ species * totalpara + standard.length,
                        family = gaussian(link = "identity"),
                        data = beh_data_nozeros_wes
                        )

mod_full_poisson_wes <- glm(total.time.open.after ~ species * totalpara + standard.length,
                        family = poisson(link = "log"),
                        data = beh_data_nozeros_wes
                        )

mod_full_nbin_wes <- glm.nb(total.time.open.after ~ species * totalpara + standard.length,
                        data = beh_data_nozeros_wes
                        )

# let's compare dispersion
check_overdispersion(mod_full_gaussian_wes) # data is not over dispersed
check_overdispersion(mod_full_poisson_wes) # data is over dispersed
check_overdispersion(mod_full_nbin_wes) # data is not over dispersed

lrtest(mod_full_gaussian_wes, mod_full_nbin_wes) # there is a sig difference between the two, with nbin having a lower loglik
```

Ok, so for the count model we'll use a negative binomial distribution.

Now, let's do some backwards model selection for the count model.
```{r}
# interaction model
mod_full_nbin_wes <- glm.nb(total.time.open.after ~ species * totalpara + standard.length,
                        data = beh_data_nozeros_wes
                        )

# dropping length
mod_nolength_nbin_wes <- glm.nb(total.time.open.after ~ species* totalpara,
                        data = beh_data_nozeros_wes
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_full_nbin_wes, mod_nolength_nbin_wes) # no sig difference, so let's drop standard length

# no interaction model
mod_combined_nbin_wes <- glm.nb(total.time.open.after ~ species + totalpara,
                        data = beh_data_nozeros_wes
                        )
# test 2-way with log likelihood ratio test
lrtest(mod_nolength_nbin_wes, mod_combined_nbin_wes) # no sig difference, so let's go with the simpler, combined model
```

Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_combined_nbin_wes)

# then you can plot them
plot(sim.output) # these look fine

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # all look ok

check_overdispersion(mod_combined_nbin_wes) # no overdispersion detected.
```

###### Wes Binary model

Now, let's look at the zero inflated model.
```{r}
# now, let's test which distribution is best

mod_full_zi_binom_wes <- glm(binary.status ~ species * totalpara + standard.length,
                         family = binomial(link = "logit"),
                        data = wes_data
                        )

mod_full_zi_poisson_wes <- glm(binary.status ~ species * totalpara + standard.length,
                        family = poisson(link = "log"),
                        data = wes_data
                        )
                        

mod_full_zi_nbin_wes <- glm.nb(binary.status ~ species * totalpara + standard.length,
                          data = wes_data) # warning error about iteration limit indicates data is underdispersed. This is confirmed with the dispersion test below.

# let's compare dispersion
check_overdispersion(mod_full_zi_binom_wes) # data is not over dispersed
check_overdispersion(mod_full_zi_poisson_wes) # data is not over dispersed
check_overdispersion(mod_full_zi_nbin_wes) # data is under dispersed

lrtest(mod_full_zi_binom_wes, mod_full_zi_poisson_wes) # significant difference, and the binomial model has a lower log lik
```

Ok, I'm going to go ahead with the binomial model since that makes more sense here and seems "good enough".

Now, let's do some backwards model selection for the binomial model.
```{r}
# interaction model
mod_full_zi_binom_wes <- glm(binary.status ~ species * totalpara + standard.length,
                         family = binomial(link = "logit"),
                        data = wes_data
                        )
# dropping length
mod_nolength_zi_binom_wes <- glm(binary.status ~ species * totalpara,
                         family = binomial(link = "logit"),
                        data = wes_data
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_full_zi_binom_wes, mod_nolength_zi_binom_wes) # no sig difference, so let's go with the simpler, combined model

# no interaction model
mod_combined_zi_binom_wes <- glm(binary.status ~ species + totalpara,
                         family = binomial(link = "logit"),
                        data = wes_data
                        )

# test 2-way with log likelihood ratio test
lrtest(mod_nolength_zi_binom_wes, mod_combined_zi_binom_wes) # sig difference, so lets go with the nolength interaction model
```

Let's check those assumptions.
```{r}
# checking assumptions for the combined model
# First we have to simulate your residuals
sim.output <- DHARMa::simulateResiduals(mod_nolength_zi_binom_wes)

# then you can plot them
plot(sim.output) # looks ok

# gives you a bunch of tests of dispersion etc
DHARMa::testResiduals(sim.output) # looks ok

# check dispersion of combined
check_overdispersion(mod_nolength_zi_binom_wes) # no overdispersion detected.
```

###### Wes Conclusions
Let's take a look at our final models.
```{r}
summary(mod_combined_nbin_wes) # species significant (est = -0.447, SE = 0.210, p = 0.033)

summary(mod_nolength_zi_binom_wes) # species significant (est = -1.2792, SE = 0., p = 0.068
```

## Figures

### Parasites

Let's create a figure that shows the difference in parasite loads between sites and species.
```{r}
# capping the dataset so that all values over 100 are equal to 101
parasite_data$totalpara_capped <- pmin(parasite_data$totalpara, 100)

# also trying a log frequency transformation
parasite_data_freq <- parasite_data %>% 
  group_by(species, site.id) %>% 
  count(totalpara, name = "freq") %>% 
  mutate(log_freq = log(freq))

# making the brownsville histogram
para_br_hist <- parasite_data %>% 
  filter(site.id == "Brownsville") %>% 
  ggplot(mapping = aes(totalpara_capped, fill = species)) +
  geom_histogram(position = "identity",
                 alpha = 0.5,
                 binwidth = 1) +
  facet_wrap(vars(site.id)) +
  labs(x = "Number of parasites",
       y = "Frequency") +
  coord_cartesian(ylim = c(0, 20)) +
  scale_fill_discrete(name = "Species") +
  scale_x_continuous(breaks = c(seq(0, 99, 20), 100),
                     labels = c(seq(0, 99, 20), "\u2265100")) +
  theme_classic()
para_br_hist

# save it
ggsave("para_br_hist.jpg", width = 6, height = 2)

para_wes_hist <- parasite_data %>% 
  filter(site.id == "Weslaco") %>% 
  ggplot(mapping = aes(totalpara_capped, fill = species)) +
  geom_histogram(position = "identity",
                 alpha = 0.5,
                 binwidth = 1) +
  facet_wrap(vars(site.id)) +
  labs(x = "Number of parasites",
       y = "Frequency") +
  coord_cartesian(ylim = c(0, 20)) +
  scale_fill_discrete(name = "Species") +
  scale_x_continuous(breaks = c(seq(0, 99, 20), 100),
                     labels = c(seq(0, 99, 20), "\u2265100")) +
  theme_classic()
para_wes_hist

# save it
ggsave("para_wes_hist.jpg", width = 6, height = 2)
```

Graph showing the proportion of fish with and without parasites.
```{r}
# summarize data
parasite_data_sum <- parasite_data %>%
  group_by(species, site.id) %>%
  summarize(prop_present = mean(para_binary), .groups = "drop")

#plot data
ggplot(parasite_data_sum, aes(x = site.id, y = prop_present, fill = species)) +
  geom_col(position = "dodge",
           alpha = 0.5) +
  labs(y = "Proportion of fish with parasites", x = "Site") +
  scale_y_continuous(limits = c(0,1)) +
  theme_classic()

# ggplot(parasite_data, aes(x = species, fill = factor(para_binary))) +
#   geom_bar(position = "fill") +
#   labs(fill = "Binary", y = "Proportion of fish with parasites") +
#   facet_wrap(~site.id) +
#   theme_minimal()

# save it
ggsave("para_prop.jpg", width = 5, height = 4)
```


### Behavior

Let's look at the difference in average behavior before/after by site.

```{r}
beh_site_boxplot <- all_data_long %>% 
  filter(prop.type != "prop.open.after") %>% 
  ggplot(mapping = aes(
    x = species,
    y = proportion,
    fill = species)) +
  geom_boxplot(aes(alpha = 0.25)) +
  geom_jitter(aes(alpha = 0.25)) +
  facet_wrap(vars(site.id)) +
  labs(x = "",
       y = "Proportion of time in the open after cue") +
  scale_fill_discrete(name = "") +
  scale_alpha(guide = "none") +
  theme_classic()
beh_site_boxplot

# save it
ggsave("beh_site_boxplot.jpg", width = 5, height = 3)

beh_sp_boxplot <- all_data_long %>% 
  filter(prop.type != "prop.open") %>% 
  ggplot(mapping = aes(
    x = species,
    y = proportion,
    fill = species)) +
  geom_boxplot() +
  geom_jitter(aes(alpha = 0.25)) +
  labs(x = "",
       y = "Total proportion of time in the open") +
  scale_fill_discrete(name = "") +
  scale_alpha(guide = "none") +
  theme_classic()
beh_sp_boxplot

# save it
ggsave("beh_site_boxplot.jpg", width = 5, height = 3)

```

Now, let's look at the relationship between parasite and species by site.
```{r}
beh_para_br_lm <- all_data %>% 
  filter(site.id == "Brownsville") %>% 
  ggplot(mapping = aes(
    x = totalpara,
    y = total.time.open.after,
    fill = species)) +
  geom_point(aes(alpha = 0.15)) +
  geom_smooth(method = 'lm') +
  facet_wrap(vars(site.id)) +
  labs(x = "Number of parasites",
       y = "Time in the open after startle (s)") +
  coord_cartesian(ylim = c(-210, 610)) +
  scale_fill_discrete(name = "Species") +
  scale_alpha(guide = "none") +
  theme_classic()

# save it
beh_para_br_lm
ggsave("beh_para_br_lm.jpg", width = 5, height = 4)

beh_para_wes_lm <- all_data %>% 
  filter(site.id == "Weslaco") %>% 
  ggplot(mapping = aes(
    x = totalpara,
    y = total.time.open.after,
    fill = species)) +
  geom_point(aes(alpha = 0.15)) +
  geom_smooth(method = 'lm') +
  facet_wrap(vars(site.id)) +
  labs(x = "Number of parasites",
       y = "Time in the open after startle (s)") +
  coord_cartesian(ylim = c(-210, 610)) +
  scale_fill_discrete(name = "Species") +
  scale_alpha(guide = "none") +
  theme_classic()
beh_para_wes_lm

# save it
beh_para_wes_lm
ggsave("beh_para_wes_lm.jpg", width = 5, height = 4)

beh_para_wes_br <- all_data %>% 
  filter(site.id == "Brownsville") %>% 
  ggplot(mapping = aes(
    x = totalpara,
    y = total.time.open.after,
    fill = species)) +
  geom_point(aes(alpha = 0.25)) +
  geom_smooth(method = 'lm') +
  labs(x = "Number of parasites",
       y = "Time in the open after startle (s)") +
  scale_fill_discrete(name = "Species") +
  scale_alpha(guide = "none") +
  theme_classic()
beh_para_site_br

beh_para_site_wes <- all_data %>% 
  filter(site.id == "Weslaco") %>% 
  ggplot(mapping = aes(
    x = totalpara,
    y = total.time.open.after,
    fill = species)) +
  geom_point(aes(alpha = 0.25)) +
  geom_smooth(method = 'lm') +
  labs(x = "Number of parasites",
       y = "Time in the open after startle (s)") +
  scale_fill_discrete(name = "Species") +
  scale_alpha(guide = "none") +
  theme_classic()
beh_para_site_wes
```

Let's also take a peek at the changes on an individual basis.
```{r}
beh_indiv_pf1 <- all_data_long %>% 
  filter(trial.id == "1") %>% 
  filter(species == "P. formosa") %>% 
  filter(prop.type == "prop.open.b4" | prop.type == "prop.open.after") %>% 
  ggplot(mapping = aes(
    x = prop.type,
    y = proportion,
    group = fish.id)) +
  geom_line(aes(color = fish.id)) +
  geom_point()
beh_indiv_pf1

beh_indiv_pf2 <- all_data_long %>% 
  filter(trial.id == "2") %>% 
  filter(species == "P. formosa") %>% 
  filter(prop.type == "prop.open.b4" | prop.type == "prop.open.after") %>% 
  ggplot(mapping = aes(
    x = prop.type,
    y = proportion,
    group = fish.id)) +
  geom_line(aes(color = fish.id)) +
  geom_point()
beh_indiv_pf2

beh_indiv_pl1 <- all_data_long %>% 
  filter(trial.id == "1") %>% 
  filter(species == "P. latipinna") %>% 
  filter(prop.type == "prop.open.b4" | prop.type == "prop.open.after") %>% 
  ggplot(mapping = aes(
    x = prop.type,
    y = proportion,
    group = fish.id)) +
  geom_line(aes(color = fish.id)) +
  geom_point()
beh_indiv_pl1

beh_indiv_pl2 <- all_data_long %>% 
  filter(trial.id == "2") %>% 
  filter(species == "P. latipinna") %>% 
  filter(prop.type == "prop.open.b4" | prop.type == "prop.open.after") %>% 
  ggplot(mapping = aes(
    x = prop.type,
    y = proportion,
    group = fish.id)) +
  geom_line(aes(color = fish.id)) +
  geom_point()
beh_indiv_pl2
```

Graph showing the proportion of fish that entered the open half of the arena
```{r}
# summarize data
all_data_sum <- all_data %>%
  group_by(species, site.id) %>%
  summarize(prop_open = mean(binary.status), .groups = "drop")

#plot data
ggplot(all_data_sum, aes(x = site.id, y = prop_open, fill = species)) +
  geom_col(position = "dodge",
           alpha = 0.5) +
  labs(y = "Proportion of fish that entered open half of arena", x = "Site") +
  scale_y_continuous(limits = c(0,1)) +
  theme_classic()

# ggplot(parasite_data, aes(x = species, fill = factor(para_binary))) +
#   geom_bar(position = "fill") +
#   labs(fill = "Binary", y = "Proportion of fish with parasites") +
#   facet_wrap(~site.id) +
#   theme_minimal()

# save it
ggsave("beh_prop.jpg", width = 5, height = 4)
